{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "def extract_time(data, time_column):\n",
    "    '''This function assumes that time is in a datetime format. \n",
    "        It takes this datetime column and extracts the following in a sin_cos format:\n",
    "        - Month\n",
    "        - Day of week\n",
    "        - Hour\n",
    "    '''\n",
    "    _data = data.copy()\n",
    "    # Extracting month, day of week, and hour from the datetime column\n",
    "    _data['Month_sin'] = np.sin(2 * np.pi * data[time_column].dt.month / 12)\n",
    "    _data['Month_cos'] = np.cos(2 * np.pi * data[time_column].dt.month / 12)\n",
    "    \n",
    "    _data['DayOfWeek_sin'] = np.sin(2 * np.pi * data[time_column].dt.dayofweek / 7)\n",
    "    _data['DayOfWeek_cos'] = np.cos(2 * np.pi * data[time_column].dt.dayofweek / 7)\n",
    "    \n",
    "    _data['Hour_sin'] = np.sin(2 * np.pi * data[time_column].dt.hour / 24)\n",
    "    _data['Hour_cos'] = np.cos(2 * np.pi * data[time_column].dt.hour / 24)\n",
    "    \n",
    "    # Dropping the original time column\n",
    "    # data.drop(columns=[time_column], inplace=True) # Uncomment if you want to drop the original time column\n",
    "    \n",
    "    return _data\n",
    "\n",
    "def lag_agg_day(data, time_column, groupby_variable, variable, n_lags, agg_method, new_col_name):\n",
    "    '''Lags and aggregates data based on the day without considering day of the week.\n",
    "    It applies aggregation methods like mean or sum based on the agg_method parameter.'''\n",
    "    _data = data.copy()\n",
    "    _data.set_index(time_column, inplace=True)\n",
    "    if agg_method == 'mean':\n",
    "        _data[new_col_name] = _data.groupby([_data.index.hour, groupby_variable], sort=False)[variable].transform(lambda x: x.shift(1).rolling(n_lags).mean())\n",
    "    elif agg_method =='sum':\n",
    "        _data[new_col_name] = _data.groupby([_data.index.hour, groupby_variable], sort=False)[variable].transform(lambda x: x.shift(1).rolling(n_lags).sum())\n",
    "    _data.reset_index(inplace=True)\n",
    "    return _data\n",
    "\n",
    "def lag_agg_dayofweek(data, time_column, groupby_variable, variable, n_lags, agg_method, new_col_name):\n",
    "    '''Lags and aggregates data based on the day of the week.\n",
    "    It applies aggregation methods like mean or sum based on the agg_method parameter.'''\n",
    "    _data = data.copy()\n",
    "    _data.set_index(time_column, inplace=True)\n",
    "    if agg_method == 'mean':\n",
    "        _data[new_col_name] = _data.groupby([_data.index.hour, _data.index.dayofweek, groupby_variable], sort=False)[variable].transform(lambda x: x.shift(1).rolling(n_lags).mean())\n",
    "    elif agg_method =='sum':\n",
    "        _data[new_col_name] = _data.groupby([_data.index.hour, _data.index.dayofweek, groupby_variable], sort=False)[variable].transform(lambda x: x.shift(1).rolling(n_lags).sum())\n",
    "    _data.reset_index(inplace=True)\n",
    "    return _data\n",
    "\n",
    "def lag_agg(data, time_column, groupby_variable, variable, n_lags, agg_method, new_col_name):\n",
    "    '''Lags and aggregates data based on a specified variable.\n",
    "    It applies aggregation methods like mean or sum based on the agg_method parameter.'''\n",
    "    _data = data.copy()\n",
    "    _data.set_index(time_column, inplace=True)\n",
    "    if agg_method == 'mean':\n",
    "        _data[new_col_name] = _data.groupby([groupby_variable], sort=False)[variable].transform(lambda x: x.rolling(n_lags).mean())\n",
    "    elif agg_method =='sum':\n",
    "        _data[new_col_name] = _data.groupby([groupby_variable], sort=False)[variable].transform(lambda x: x.rolling(n_lags).sum())\n",
    "    _data.reset_index(inplace=True)\n",
    "    return _data\n",
    "\n",
    "def hour_agg(data, groupby_columns, time_column, value_column):\n",
    "    \"\"\"\n",
    "    Perform hourly aggregation on the specified DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - data: DataFrame to be aggregated.\n",
    "    - groupby_columns: List of columns to group by.\n",
    "    - time_column: Name of the time column.\n",
    "    - value_column: Name of the column to aggregate.\n",
    "\n",
    "    Returns:\n",
    "    - Aggregated DataFrame.\n",
    "    \"\"\"\n",
    "    return (\n",
    "        data.groupby([*groupby_columns, data[time_column].dt.round('H')], sort=False)\n",
    "            .agg({value_column: 'sum'})\n",
    "            .reset_index()\n",
    "    )\n",
    "\n",
    "def _fill_missing_dates(df: pd.DataFrame, min_date: pd.Timestamp, max_date: pd.Timestamp) -> pd.DataFrame:\n",
    "    \"\"\"Fill missing dates in the time series between the minimum and maximum dates and set their\n",
    "    values to NaN.\n",
    "\n",
    "    :param df: Time series sales data for a specific country-brand.\n",
    "    :param min_date: Minimum date to be considered.\n",
    "    :param max_date: Maximum date to be considered.\n",
    "    :return: Complete time series for a specific country-type.\n",
    "    \"\"\"\n",
    "\n",
    "    df['Time'] = pd.to_datetime(df['Time'])\n",
    "    complete_date_range = pd.date_range(start=min_date, end=max_date, freq='H')\n",
    "    complete_df = (\n",
    "        pd.DataFrame({'Time': complete_date_range})\n",
    "        .merge(df[['CountryID']].drop_duplicates(), how='cross')\n",
    "    )\n",
    "    result_df = complete_df.merge(df, on=['Time', 'CountryID'], how='left')\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None) \n",
    "\n",
    "load_data = pd.read_csv('C:\\\\Users\\\\RULLFLL1\\\\SE_competition\\\\SE_Competition\\\\data\\\\master_load.csv').drop('Unnamed: 0', axis=1)\n",
    "gen_data = pd.read_csv('C:\\\\Users\\\\RULLFLL1\\\\SE_competition\\\\SE_Competition\\\\data\\\\master_gen.csv').drop('Unnamed: 0', axis=1)\n",
    "\n",
    "# datetime objects\n",
    "load_data['Time'] = pd.to_datetime(load_data.Time)\n",
    "gen_data['Time'] = pd.to_datetime(gen_data.Time)\n",
    "\n",
    "# drop column\n",
    "gen_data.drop(['AreaID', 'UnitName'], axis=1, inplace=True)\n",
    "load_data.drop(['AreaID', 'PsrType', 'UnitName'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = {'load_data': load_data, 'gen_data': gen_data}\n",
    "\n",
    "for name, df in all_data.items():\n",
    "    if 'PsrType' in df.columns:\n",
    "        all_data[name] = hour_agg(df, ['CountryID', 'PsrType'], 'Time', 'quantity')\n",
    "    else:\n",
    "        all_data[name] = hour_agg(df, ['CountryID'], 'Time', 'quantity')\n",
    "\n",
    "load_data = all_data['load_data']\n",
    "gen_data = all_data['gen_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "datetime_series = pd.date_range(start=load_data.Time.min(), end=load_data.Time.max(), freq='H')\n",
    "\n",
    "# Creating a range from 0 to 9\n",
    "numbers_range = load_data.CountryID.unique()\n",
    "\n",
    "# Creating a multi-index from cartesian product of both ranges\n",
    "index = pd.MultiIndex.from_product([datetime_series, numbers_range], names=['Time', 'CountryID'])\n",
    "\n",
    "# Creating a DataFrame with the multi-index\n",
    "df_index = pd.DataFrame(index=index).reset_index()\n",
    "\n",
    "load_data_full = df_index.merge(load_data, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gen Data\n",
    "datetime_series = pd.date_range(start=gen_data.Time.min(), end=gen_data.Time.max(), freq='H')\n",
    "numbers_range = gen_data.CountryID.unique()\n",
    "psr_vals = gen_data.PsrType.unique()\n",
    "\n",
    "# Creating a multi-index from cartesian product of both ranges\n",
    "index = pd.MultiIndex.from_product([datetime_series, numbers_range, psr_vals], names=['Time', 'CountryID', 'PsrType'])\n",
    "\n",
    "# Creating a DataFrame with the multi-index\n",
    "df_index = pd.DataFrame(index=index).reset_index()\n",
    "\n",
    "gen_data_full = df_index.merge(gen_data, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that I'm simply filling missing values as zero. May need to reconsider\n",
    "gen_data_full = gen_data_full.pivot_table(index = ['Time','CountryID'], columns= ['PsrType'], values='quantity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CountryID</th>\n",
       "      <th>Time</th>\n",
       "      <th>load</th>\n",
       "      <th>B01</th>\n",
       "      <th>B02</th>\n",
       "      <th>B03</th>\n",
       "      <th>B04</th>\n",
       "      <th>B05</th>\n",
       "      <th>B06</th>\n",
       "      <th>B07</th>\n",
       "      <th>...</th>\n",
       "      <th>B11</th>\n",
       "      <th>B12</th>\n",
       "      <th>B13</th>\n",
       "      <th>B14</th>\n",
       "      <th>B15</th>\n",
       "      <th>B16</th>\n",
       "      <th>B17</th>\n",
       "      <th>B18</th>\n",
       "      <th>B19</th>\n",
       "      <th>B20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>42196.0</td>\n",
       "      <td>4333.0</td>\n",
       "      <td>3565.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2634.0</td>\n",
       "      <td>2053.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1424.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3351.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>846.0</td>\n",
       "      <td>5688.0</td>\n",
       "      <td>24850.0</td>\n",
       "      <td>333.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>3314.0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>215.0</td>\n",
       "      <td>331.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>1875.0</td>\n",
       "      <td>1308.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>4254.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>328.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>504.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>126.0</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>21121.0</td>\n",
       "      <td>677.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>517.0</td>\n",
       "      <td>6234.0</td>\n",
       "      <td>1465.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2115.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>1365.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>10326.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>2302.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>485.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>410.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1516.0</td>\n",
       "      <td>3568.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CountryID       Time     load     B01     B02    B03     B04     B05  \\\n",
       "0          2 2022-01-01  42196.0  4333.0  3565.0    NaN  2634.0  2053.0   \n",
       "1          3 2022-01-01   3314.0   468.0     NaN    NaN   215.0   331.0   \n",
       "2          5 2022-01-01   4254.0   132.0   328.0    NaN   504.0     0.0   \n",
       "3          6 2022-01-01  21121.0   677.0     NaN  517.0  6234.0  1465.0   \n",
       "4          8 2022-01-01  10326.0    21.0     NaN    NaN  2019.0  2302.0   \n",
       "\n",
       "     B06  B07  ...     B11    B12  B13     B14    B15  B16    B17     B18  \\\n",
       "0  279.0  NaN  ...  1424.0  119.0  NaN  3351.0  126.0  0.0  846.0  5688.0   \n",
       "1   37.0  NaN  ...     NaN    NaN  NaN     NaN    NaN  1.0  169.0  1875.0   \n",
       "2    0.0  NaN  ...    11.0    9.0  NaN  1950.0    7.0  0.0   15.0     NaN   \n",
       "3  202.0  NaN  ...  2115.0  242.0  NaN     NaN    NaN  0.0   36.0     NaN   \n",
       "4    NaN  NaN  ...     0.0    NaN  NaN   485.0    NaN  1.0  410.0  2016.0   \n",
       "\n",
       "       B19     B20  \n",
       "0  24850.0   333.0  \n",
       "1   1308.0     NaN  \n",
       "2    126.0    69.0  \n",
       "3   2024.0  1365.0  \n",
       "4   1516.0  3568.0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merging load and gen\n",
    "data = load_data_full.rename({'quantity':'load'}, axis=1).set_index(['CountryID','Time']).merge(gen_data_full, left_index=True, right_index=True)\n",
    "data = data.reset_index()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fill_missing_dates(df: pd.DataFrame, min_date: pd.Timestamp, max_date: pd.Timestamp) -> pd.DataFrame:\n",
    "    \"\"\"Fill missing dates in the time series between the minimum and maximum dates and set their\n",
    "    values to NaN.\n",
    "\n",
    "    :param df: Time series sales data for a specific country-brand.\n",
    "    :param min_date: Minimum date to be considered.\n",
    "    :param max_date: Maximum date to be considered.\n",
    "    :return: Complete time series for a specific country-type.\n",
    "    \"\"\"\n",
    "\n",
    "    df['Time'] = pd.to_datetime(df['Time'])\n",
    "    complete_date_range = pd.date_range(start=min_date, end=max_date, freq='H')\n",
    "    complete_df = (\n",
    "        pd.DataFrame({'Time': complete_date_range})\n",
    "        .merge(df[['CountryID']].drop_duplicates(), how='cross')\n",
    "    )\n",
    "    result_df = complete_df.merge(df, on=['Time', 'CountryID'], how='left')\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>CountryID</th>\n",
       "      <th>load</th>\n",
       "      <th>B01</th>\n",
       "      <th>B02</th>\n",
       "      <th>B03</th>\n",
       "      <th>B04</th>\n",
       "      <th>B05</th>\n",
       "      <th>B06</th>\n",
       "      <th>B07</th>\n",
       "      <th>...</th>\n",
       "      <th>B11</th>\n",
       "      <th>B12</th>\n",
       "      <th>B13</th>\n",
       "      <th>B14</th>\n",
       "      <th>B15</th>\n",
       "      <th>B16</th>\n",
       "      <th>B17</th>\n",
       "      <th>B18</th>\n",
       "      <th>B19</th>\n",
       "      <th>B20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>2</td>\n",
       "      <td>42196.0</td>\n",
       "      <td>4333.0</td>\n",
       "      <td>3565.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2634.0</td>\n",
       "      <td>2053.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1424.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3351.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>846.0</td>\n",
       "      <td>5688.0</td>\n",
       "      <td>24850.0</td>\n",
       "      <td>333.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>3</td>\n",
       "      <td>3314.0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>215.0</td>\n",
       "      <td>331.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>1875.0</td>\n",
       "      <td>1308.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>5</td>\n",
       "      <td>4254.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>328.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>504.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>126.0</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>6</td>\n",
       "      <td>21121.0</td>\n",
       "      <td>677.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>517.0</td>\n",
       "      <td>6234.0</td>\n",
       "      <td>1465.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2115.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>1365.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>8</td>\n",
       "      <td>10326.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>2302.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>485.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>410.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1516.0</td>\n",
       "      <td>3568.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78844</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>8</td>\n",
       "      <td>29551.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3412.0</td>\n",
       "      <td>3789.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1458.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1223.0</td>\n",
       "      <td>3633.0</td>\n",
       "      <td>5343.0</td>\n",
       "      <td>14844.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78845</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78846</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78847</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>39824.0</td>\n",
       "      <td>336.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5732.0</td>\n",
       "      <td>644.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1872.0</td>\n",
       "      <td>4340.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12928.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>464.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12028.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78848</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>222.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>146.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78849 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time  CountryID     load     B01     B02    B03     B04     B05  \\\n",
       "0     2022-01-01          2  42196.0  4333.0  3565.0    NaN  2634.0  2053.0   \n",
       "1     2022-01-01          3   3314.0   468.0     NaN    NaN   215.0   331.0   \n",
       "2     2022-01-01          5   4254.0   132.0   328.0    NaN   504.0     0.0   \n",
       "3     2022-01-01          6  21121.0   677.0     NaN  517.0  6234.0  1465.0   \n",
       "4     2022-01-01          8  10326.0    21.0     NaN    NaN  2019.0  2302.0   \n",
       "...          ...        ...      ...     ...     ...    ...     ...     ...   \n",
       "78844 2023-01-01          8  29551.0   135.0     NaN    NaN  3412.0  3789.0   \n",
       "78845 2023-01-01          7      NaN     NaN     NaN    NaN     NaN     NaN   \n",
       "78846 2023-01-01          4      NaN     NaN     NaN    NaN     NaN     NaN   \n",
       "78847 2023-01-01          0  39824.0   336.0     0.0    0.0  5732.0   644.0   \n",
       "78848 2023-01-01          1      NaN     NaN     NaN    NaN   222.0     0.0   \n",
       "\n",
       "         B06  B07  ...     B11     B12  B13      B14    B15   B16     B17  \\\n",
       "0      279.0  NaN  ...  1424.0   119.0  NaN   3351.0  126.0   0.0   846.0   \n",
       "1       37.0  NaN  ...     NaN     NaN  NaN      NaN    NaN   1.0   169.0   \n",
       "2        0.0  NaN  ...    11.0     9.0  NaN   1950.0    7.0   0.0    15.0   \n",
       "3      202.0  NaN  ...  2115.0   242.0  NaN      NaN    NaN   0.0    36.0   \n",
       "4        NaN  NaN  ...     0.0     NaN  NaN    485.0    NaN   1.0   410.0   \n",
       "...      ...  ...  ...     ...     ...  ...      ...    ...   ...     ...   \n",
       "78844    NaN  NaN  ...     0.0     NaN  NaN   1458.0    NaN   6.0  1223.0   \n",
       "78845    NaN  NaN  ...     NaN     NaN  NaN      NaN    NaN   NaN     NaN   \n",
       "78846    NaN  NaN  ...     NaN     NaN  NaN      NaN    NaN   NaN     NaN   \n",
       "78847   80.0  0.0  ...  1872.0  4340.0  0.0  12928.0  160.0  40.0   464.0   \n",
       "78848    0.0  NaN  ...     NaN     NaN  NaN      NaN    NaN   NaN     NaN   \n",
       "\n",
       "          B18      B19      B20  \n",
       "0      5688.0  24850.0    333.0  \n",
       "1      1875.0   1308.0      NaN  \n",
       "2         NaN    126.0     69.0  \n",
       "3         NaN   2024.0   1365.0  \n",
       "4      2016.0   1516.0   3568.0  \n",
       "...       ...      ...      ...  \n",
       "78844  3633.0   5343.0  14844.0  \n",
       "78845     NaN      NaN      NaN  \n",
       "78846     NaN      NaN      NaN  \n",
       "78847     0.0  12028.0     24.0  \n",
       "78848     NaN    146.0      0.0  \n",
       "\n",
       "[78849 rows x 23 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean = _fill_missing_dates(data,min_date=data['Time'].min(),max_date=data['Time'].max())\n",
    "data_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_green_energy(df):\n",
    "    green_energy = ['B01', 'B09', 'B10', 'B11', 'B12', 'B13', 'B14', 'B15', 'B16', 'B17', 'B18', 'B19']\n",
    "    df['green_energy'] = df[green_energy].sum(axis=1, skipna=True)\n",
    "    df = df[['Time', 'CountryID', 'load', 'green_energy']]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean_2 = data_clean.groupby(['Time', 'CountryID']).apply(calculate_green_energy)\n",
    "\n",
    "data_clean_2 = data_clean_2.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pivot_and_flatten(df, index_col, country_col, value_cols, aggfunc='first'):\n",
    "    \"\"\"\n",
    "    Pivot the DataFrame from long to wide, flatten multi-level columns, and reset the index.\n",
    "\n",
    "    Parameters:\n",
    "    - df: Input DataFrame.\n",
    "    - index_col: Column to be used as the index in the wide DataFrame.\n",
    "    - country_col: Column to be used as columns in the wide DataFrame.\n",
    "    - value_cols: List of columns to be used as values in the wide DataFrame.\n",
    "    - aggfunc: Aggregation function for pivot_table.\n",
    "\n",
    "    Returns:\n",
    "    - Wide DataFrame with flattened columns and reset index.\n",
    "    \"\"\"\n",
    "    # Pivot the DataFrame from long to wide\n",
    "    wide_df = df.pivot_table(index=index_col, columns=country_col, values=value_cols, aggfunc=aggfunc)\n",
    "\n",
    "    # Flatten the multi-level columns\n",
    "    wide_df.columns = [f'{col}_{country}' for col, country in wide_df.columns]\n",
    "\n",
    "    # Resetting the index\n",
    "    wide_df = wide_df.reset_index()\n",
    "\n",
    "    return wide_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean_wide = pivot_and_flatten(data_clean_2, index_col='Time', country_col='CountryID', value_cols=['green_energy', 'load'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>green_energy_0</th>\n",
       "      <th>green_energy_1</th>\n",
       "      <th>green_energy_2</th>\n",
       "      <th>green_energy_3</th>\n",
       "      <th>green_energy_4</th>\n",
       "      <th>green_energy_5</th>\n",
       "      <th>green_energy_6</th>\n",
       "      <th>green_energy_7</th>\n",
       "      <th>green_energy_8</th>\n",
       "      <th>load_0</th>\n",
       "      <th>load_1</th>\n",
       "      <th>load_2</th>\n",
       "      <th>load_3</th>\n",
       "      <th>load_4</th>\n",
       "      <th>load_5</th>\n",
       "      <th>load_6</th>\n",
       "      <th>load_7</th>\n",
       "      <th>load_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01 00:00:00</td>\n",
       "      <td>17603.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43598.0</td>\n",
       "      <td>3821.0</td>\n",
       "      <td>16902.0</td>\n",
       "      <td>2250.0</td>\n",
       "      <td>5837.0</td>\n",
       "      <td>4641.0</td>\n",
       "      <td>4449.0</td>\n",
       "      <td>20827.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42196.0</td>\n",
       "      <td>3314.0</td>\n",
       "      <td>15331.0</td>\n",
       "      <td>4254.0</td>\n",
       "      <td>21121.0</td>\n",
       "      <td>14438.0</td>\n",
       "      <td>10326.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-01 01:00:00</td>\n",
       "      <td>17184.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>174116.0</td>\n",
       "      <td>3774.0</td>\n",
       "      <td>16946.0</td>\n",
       "      <td>9228.0</td>\n",
       "      <td>5781.0</td>\n",
       "      <td>4491.0</td>\n",
       "      <td>16327.0</td>\n",
       "      <td>19530.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>165125.0</td>\n",
       "      <td>3218.0</td>\n",
       "      <td>15331.0</td>\n",
       "      <td>16457.0</td>\n",
       "      <td>19756.0</td>\n",
       "      <td>13935.0</td>\n",
       "      <td>40706.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-01 02:00:00</td>\n",
       "      <td>17497.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>168446.0</td>\n",
       "      <td>3478.0</td>\n",
       "      <td>16875.0</td>\n",
       "      <td>9374.0</td>\n",
       "      <td>6264.0</td>\n",
       "      <td>4436.0</td>\n",
       "      <td>14713.0</td>\n",
       "      <td>18383.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>160415.0</td>\n",
       "      <td>3126.0</td>\n",
       "      <td>15270.0</td>\n",
       "      <td>15426.0</td>\n",
       "      <td>18685.0</td>\n",
       "      <td>13579.0</td>\n",
       "      <td>39465.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-01 03:00:00</td>\n",
       "      <td>17712.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>164624.0</td>\n",
       "      <td>3212.0</td>\n",
       "      <td>16349.0</td>\n",
       "      <td>9406.0</td>\n",
       "      <td>6442.0</td>\n",
       "      <td>4568.0</td>\n",
       "      <td>14893.0</td>\n",
       "      <td>17680.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>158035.0</td>\n",
       "      <td>3080.0</td>\n",
       "      <td>15150.0</td>\n",
       "      <td>14781.0</td>\n",
       "      <td>18124.0</td>\n",
       "      <td>13397.0</td>\n",
       "      <td>38923.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-01 04:00:00</td>\n",
       "      <td>17605.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>158479.0</td>\n",
       "      <td>3021.0</td>\n",
       "      <td>16609.0</td>\n",
       "      <td>9138.0</td>\n",
       "      <td>5797.0</td>\n",
       "      <td>4559.0</td>\n",
       "      <td>14878.0</td>\n",
       "      <td>17396.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>157016.0</td>\n",
       "      <td>3044.0</td>\n",
       "      <td>15387.0</td>\n",
       "      <td>14630.0</td>\n",
       "      <td>18400.0</td>\n",
       "      <td>13364.0</td>\n",
       "      <td>38211.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8756</th>\n",
       "      <td>2022-12-31 20:00:00</td>\n",
       "      <td>115688.0</td>\n",
       "      <td>824.0</td>\n",
       "      <td>192166.0</td>\n",
       "      <td>1902.0</td>\n",
       "      <td>15976.0</td>\n",
       "      <td>8740.0</td>\n",
       "      <td>4242.0</td>\n",
       "      <td>6959.0</td>\n",
       "      <td>20820.0</td>\n",
       "      <td>128248.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>184106.0</td>\n",
       "      <td>3713.0</td>\n",
       "      <td>14440.0</td>\n",
       "      <td>17488.0</td>\n",
       "      <td>24809.0</td>\n",
       "      <td>15211.0</td>\n",
       "      <td>45646.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8757</th>\n",
       "      <td>2022-12-31 21:00:00</td>\n",
       "      <td>65924.0</td>\n",
       "      <td>830.0</td>\n",
       "      <td>193062.0</td>\n",
       "      <td>1730.0</td>\n",
       "      <td>15383.0</td>\n",
       "      <td>8773.0</td>\n",
       "      <td>3719.0</td>\n",
       "      <td>6910.0</td>\n",
       "      <td>20854.0</td>\n",
       "      <td>69520.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>175401.0</td>\n",
       "      <td>3579.0</td>\n",
       "      <td>14201.0</td>\n",
       "      <td>17075.0</td>\n",
       "      <td>23169.0</td>\n",
       "      <td>14641.0</td>\n",
       "      <td>43425.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8758</th>\n",
       "      <td>2022-12-31 22:00:00</td>\n",
       "      <td>106916.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>191073.0</td>\n",
       "      <td>1920.0</td>\n",
       "      <td>14944.0</td>\n",
       "      <td>8689.0</td>\n",
       "      <td>3685.0</td>\n",
       "      <td>7054.0</td>\n",
       "      <td>20756.0</td>\n",
       "      <td>106396.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>168830.0</td>\n",
       "      <td>3520.0</td>\n",
       "      <td>13713.0</td>\n",
       "      <td>16717.0</td>\n",
       "      <td>21857.0</td>\n",
       "      <td>13977.0</td>\n",
       "      <td>41766.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8759</th>\n",
       "      <td>2022-12-31 23:00:00</td>\n",
       "      <td>60620.0</td>\n",
       "      <td>489.0</td>\n",
       "      <td>178308.0</td>\n",
       "      <td>2362.0</td>\n",
       "      <td>14605.0</td>\n",
       "      <td>8618.0</td>\n",
       "      <td>3466.0</td>\n",
       "      <td>5946.0</td>\n",
       "      <td>19525.0</td>\n",
       "      <td>60520.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>161541.0</td>\n",
       "      <td>3440.0</td>\n",
       "      <td>13772.0</td>\n",
       "      <td>16261.0</td>\n",
       "      <td>20555.0</td>\n",
       "      <td>13272.0</td>\n",
       "      <td>40415.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8760</th>\n",
       "      <td>2023-01-01 00:00:00</td>\n",
       "      <td>38208.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>128790.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6470.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11798.0</td>\n",
       "      <td>39824.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>115263.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11754.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29551.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8761 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Time  green_energy_0  green_energy_1  green_energy_2  \\\n",
       "0    2022-01-01 00:00:00         17603.0             0.0         43598.0   \n",
       "1    2022-01-01 01:00:00         17184.0             0.0        174116.0   \n",
       "2    2022-01-01 02:00:00         17497.0             0.0        168446.0   \n",
       "3    2022-01-01 03:00:00         17712.0             0.0        164624.0   \n",
       "4    2022-01-01 04:00:00         17605.0             0.0        158479.0   \n",
       "...                  ...             ...             ...             ...   \n",
       "8756 2022-12-31 20:00:00        115688.0           824.0        192166.0   \n",
       "8757 2022-12-31 21:00:00         65924.0           830.0        193062.0   \n",
       "8758 2022-12-31 22:00:00        106916.0           676.0        191073.0   \n",
       "8759 2022-12-31 23:00:00         60620.0           489.0        178308.0   \n",
       "8760 2023-01-01 00:00:00         38208.0           146.0        128790.0   \n",
       "\n",
       "      green_energy_3  green_energy_4  green_energy_5  green_energy_6  \\\n",
       "0             3821.0         16902.0          2250.0          5837.0   \n",
       "1             3774.0         16946.0          9228.0          5781.0   \n",
       "2             3478.0         16875.0          9374.0          6264.0   \n",
       "3             3212.0         16349.0          9406.0          6442.0   \n",
       "4             3021.0         16609.0          9138.0          5797.0   \n",
       "...              ...             ...             ...             ...   \n",
       "8756          1902.0         15976.0          8740.0          4242.0   \n",
       "8757          1730.0         15383.0          8773.0          3719.0   \n",
       "8758          1920.0         14944.0          8689.0          3685.0   \n",
       "8759          2362.0         14605.0          8618.0          3466.0   \n",
       "8760             0.0             0.0          6470.0             0.0   \n",
       "\n",
       "      green_energy_7  green_energy_8    load_0  load_1    load_2  load_3  \\\n",
       "0             4641.0          4449.0   20827.0     NaN   42196.0  3314.0   \n",
       "1             4491.0         16327.0   19530.0     NaN  165125.0  3218.0   \n",
       "2             4436.0         14713.0   18383.0     NaN  160415.0  3126.0   \n",
       "3             4568.0         14893.0   17680.0     NaN  158035.0  3080.0   \n",
       "4             4559.0         14878.0   17396.0     NaN  157016.0  3044.0   \n",
       "...              ...             ...       ...     ...       ...     ...   \n",
       "8756          6959.0         20820.0  128248.0     NaN  184106.0  3713.0   \n",
       "8757          6910.0         20854.0   69520.0     NaN  175401.0  3579.0   \n",
       "8758          7054.0         20756.0  106396.0     NaN  168830.0  3520.0   \n",
       "8759          5946.0         19525.0   60520.0     NaN  161541.0  3440.0   \n",
       "8760             0.0         11798.0   39824.0     NaN  115263.0     NaN   \n",
       "\n",
       "       load_4   load_5   load_6   load_7   load_8  \n",
       "0     15331.0   4254.0  21121.0  14438.0  10326.0  \n",
       "1     15331.0  16457.0  19756.0  13935.0  40706.0  \n",
       "2     15270.0  15426.0  18685.0  13579.0  39465.0  \n",
       "3     15150.0  14781.0  18124.0  13397.0  38923.0  \n",
       "4     15387.0  14630.0  18400.0  13364.0  38211.0  \n",
       "...       ...      ...      ...      ...      ...  \n",
       "8756  14440.0  17488.0  24809.0  15211.0  45646.0  \n",
       "8757  14201.0  17075.0  23169.0  14641.0  43425.0  \n",
       "8758  13713.0  16717.0  21857.0  13977.0  41766.0  \n",
       "8759  13772.0  16261.0  20555.0  13272.0  40415.0  \n",
       "8760      NaN  11754.0      NaN      NaN  29551.0  \n",
       "\n",
       "[8761 rows x 19 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean_wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8761 entries, 0 to 8760\n",
      "Data columns (total 19 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   Time            8761 non-null   datetime64[ns]\n",
      " 1   green_energy_0  8761 non-null   float64       \n",
      " 2   green_energy_1  8761 non-null   float64       \n",
      " 3   green_energy_2  8761 non-null   float64       \n",
      " 4   green_energy_3  8761 non-null   float64       \n",
      " 5   green_energy_4  8761 non-null   float64       \n",
      " 6   green_energy_5  8761 non-null   float64       \n",
      " 7   green_energy_6  8761 non-null   float64       \n",
      " 8   green_energy_7  8761 non-null   float64       \n",
      " 9   green_energy_8  8761 non-null   float64       \n",
      " 10  load_0          8761 non-null   float64       \n",
      " 11  load_1          1572 non-null   float64       \n",
      " 12  load_2          8761 non-null   float64       \n",
      " 13  load_3          8760 non-null   float64       \n",
      " 14  load_4          8759 non-null   float64       \n",
      " 15  load_5          8761 non-null   float64       \n",
      " 16  load_6          8760 non-null   float64       \n",
      " 17  load_7          8760 non-null   float64       \n",
      " 18  load_8          8761 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(18)\n",
      "memory usage: 1.3 MB\n"
     ]
    }
   ],
   "source": [
    "data_clean_wide.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_nans(df):\n",
    "    \"\"\"\n",
    "    Impute NaN values in a DataFrame with specific logic:\n",
    "    - If all rows in a column are missing, set the value to 0.\n",
    "    - Otherwise, impute the NaN with the mean between the previous and the following value.\n",
    "\n",
    "    Parameters:\n",
    "    - df: Input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with NaN values imputed based on the specified logic.\n",
    "    \"\"\"\n",
    "    for col in df.columns:\n",
    "        # Check if all rows in the column are missing\n",
    "        if df[col].isnull().all():\n",
    "            # Set the value to 0 if all rows are missing\n",
    "            df[col] = 0\n",
    "        elif df[col].dtype == 'datetime64[ns]':\n",
    "            # Impute NaN with the mean of the datetime values\n",
    "            df[col] = df[col].fillna(df[col].mean())\n",
    "        else:\n",
    "            # Impute NaN with the mean between the previous and the following value\n",
    "            df[col] = df[col].fillna((df[col].shift() + df[col].shift(-1)) / 2)\n",
    "\n",
    "    return df\n",
    "\n",
    "data_clean_wide_imputed = impute_nans(data_clean_wide)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
